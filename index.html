<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Jerry (Qilong) Cheng</title>
    <meta name="author" content="Jerry Cheng">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
  </head>

  <body>
    <table style="width:100%;max-width:800px;margin:auto;border-spacing:0px;">
      <tbody>
        <tr>
          <td style="padding:2.5%;width:63%;vertical-align:middle">
            <p class="name" style="text-align:center;">Jerry (Qilong) Cheng</p>
            <p>
              I am a robotics researcher and engineer passionate about developing unified policies that integrate visual perception, loco-manipulation, and dexterous control for intelligent robotic systems. My work spans reinforcement learning, control, and mechanism design for humanoid and cinematic robots. I am currently a Research Fellow at <a href="https://haosu-robotics.github.io">NYU Biomechatronics and Intelligent Robotics Lab</a> under Prof. Hao Su, and previously at the <a href="https://starslab.ca">Space and Terrestrial Autonomous Robotics Systems Lab</a> under Prof. Jonathan Kelly.
            </p>
            <p style="text-align:center">
              <a href="mailto:qilong.cheng@mail.utoronto.ca">Email</a> &nbsp;/&nbsp;
              <a href="data/Robotics_Resume-9.pdf">CV</a> &nbsp;/&nbsp;
              <a href="https://scholar.google.com/citations?user=iQuHS3MAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
              <a href="https://www.linkedin.com/in/jerry-qilong-cheng-540039163/">LinkedIn</a> &nbsp;/&nbsp;
              <a href="https://github.com/thejerrycheng">GitHub</a>
            </p>
          </td>
          <td style="padding:2.5%;width:37%;max-width:37%">
            <a href="images/jerry.jpg"><img style="width:100%;border-radius:50%;" src="images/jerry.jpg" alt="profile photo"></a>
          </td>
        </tr>
      </tbody>
    </table>

    <table style="width:100%;max-width:800px;margin:auto;border-spacing:0px;">
      <tbody>
        <tr><td><h2>Education</h2>
          <p><b>University of Toronto</b>, M.Eng. in Computer Engineering (Robotics), GPA: 3.89/4.00<br>
          <i>Sep 2023 – Aug 2025</i></p>
          <p><b>University of Toronto</b>, B.A.Sc. in Mechanical Engineering, Minor in Robotics & Business, GPA: 3.92/4.00<br>
          <i>Aug 2017 – Jun 2023</i></p>
        </td></tr>
      </tbody>
    </table>

    <table style="width:100%;max-width:800px;margin:auto;border-spacing:0px;">
      <tbody>
        <tr><td><h2>Research Interests</h2>
          <p>My research focuses on integrating learning-based control and perception for robots. Specifically, I develop reinforcement learning algorithms for visual loco-manipulation, imitation learning for exoskeletons, and vision-based control frameworks for biped and manipulator robots. I am also exploring unified policies that bridge hardware-aware and perception-driven intelligence.</p>
        </td></tr>
      </tbody>
    </table>

    <table style="width:100%;max-width:800px;margin:auto;border-spacing:0px;">
      <tbody>
        <tr><td><h2>Publications</h2></td></tr>

        <tr><td>
          <p><b>[1]</b> E. Wise, P. Kaveti, Q. Cheng, W. Wang, H. Singh, J. Kelly, D. M. Rosen, and M. Giamou, “A Certifiably Correct Algorithm for Generalized Robot-World and Hand-Eye Calibration,” <i>IJRR</i>, 2025. [<a href="https://arxiv.org/abs/2507.23045">arXiv</a>]</p>
          <p><b>[2]</b> B. Huang, S. Ren, Y. Luo, Q. Cheng, H. Cai, Y. Sang, M. Sousa, P. H. Dietz, and D. Wigdor, “VibraForge: A Scalable Prototyping Toolkit For Creating Spatialized Vibrotactile Feedback Systems,” <i>CHI</i>, 2024. [<a href="https://arxiv.org/abs/2409.17420">arXiv</a>]</p>
          <p><b>[3]</b> B. Huang, Z. Wang, Q. Cheng, S. Ren, H. Cai, A. Alvarez Valdivia, K. Mahadevan, and D. Wigdor, “AeroHaptix: A Wearable Vibrotactile Feedback System for Enhancing Collision Avoidance in UAV Teleoperation,” <i>IEEE RA-L</i>, 2024. [<a href="https://arxiv.org/abs/2407.12105">arXiv</a>]</p>
          <p><b>[4]</b> Q. Cheng, E. Wise, and J. Kelly, “Extrinsic Calibration of 2D Millimetre-Wavelength Radar Pairs Using Ego-Velocity Estimates,” <i>IEEE AIM</i>, 2023. [<a href="https://ieeexplore.ieee.org/document/10196187">IEEE</a>]</p>
          <p><b>[5]</b> E. Wise, Q. Cheng, and J. Kelly, “Spatiotemporal Calibration of 3D Millimetre-Wavelength Radar-Camera Pairs,” <i>IEEE TRO</i>, 2022. [<a href="https://ieeexplore.ieee.org/abstract/document/10256219">IEEE</a>]</p>
          <p><b>[6]</b> M. He, Q. Cheng, and G. Qi, “Weakly Supervised Semantic and Attentive Data Mixing Augmentation for Fine-Grained Visual Categorization,” <i>IEEE Access</i>, 2022. [<a href="https://ieeexplore.ieee.org/document/9745100">IEEE</a>]</p>
          <p><b>[7]</b> J. Chen, Q. Cheng, and M. Han, “Generative Design for Self-Balancing Unicycle Robot in Additive Manufacturing,” <i>SPIE ACAIB</i>, 2022. [<a href="https://nanolithography.spiedigitallibrary.org/conference-proceedings-of-spie/12253/122530A/Generative-design-for-self-balancing-unicycle-robot-in-additive-manufacturing/10.1117/12.2639454.short">SPIE</a>]</p>
        </td></tr>
      </tbody>
    </table>

    <table style="width:100%;max-width:800px;margin:auto;border-spacing:0px;">
      <tbody>
        <tr><td><h2>Research Experience</h2>
          <ul>
            <li><b>Research Fellow</b> – Biomechatronics and Intelligent Robotics Lab, NYU (Prof. Hao Su) <i>(Sep 2025 – Present)</i><br>Developed reinforcement learning and musculoskeletal simulation frameworks for exoskeleton and humanoid locomotion benchmarking.</li>
            <li><b>Robotics Researcher</b> – STARS Lab, University of Toronto (Prof. Jonathan Kelly) <i>(Sep 2021 – Aug 2025)</i><br>Developed radar-based calibration and state estimation algorithms validated on real-world driving datasets.</li>
            <li><b>HCI Researcher</b> – Dynamic Graphics Project Lab, UofT (Prof. Daniel Wigdor) <i>(Sep 2022 – Aug 2025)</i><br>Created open-source vibrotactile prototyping and wearable haptics systems integrated with UAV teleoperation.</li>
            <li><b>M.Eng Researcher</b> – UofT Robotics Institute <i>(Sep 2024 – Aug 2025)</i><br>Designed and built IRIS: a modular 6-DOF 3D-printed cinema robot arm with imitation learning and visual planning.</li>
          </ul>
        </td></tr>
      </tbody>
    </table>

    <table style="width:100%;max-width:800px;margin:auto;border-spacing:0px;">
      <tbody>
        <tr><td><h2>Technical Skills</h2>
          <p><b>Software & Tools:</b> Python, C++, MATLAB, ROS, MuJoCo, Isaac Sim, IsaacLab, PyTorch, Docker, Linux<br>
          <b>Hardware & Robots:</b> xArm, Unitree, Raspberry Pi, Jetson, Intel RealSense, Arduino, STM32, PND Adam, Booster Robot</p>
        </td></tr>
      </tbody>
    </table>
  </body>
</html>
