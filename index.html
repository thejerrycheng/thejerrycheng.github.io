<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Jerry (Qilong) Cheng</title>
    <meta name="author" content="Jerry Cheng">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    </head>


  <body>
    <body>
      <table style="width:100%;max-width:800px;margin:auto;border-spacing:0px;">
      <tbody>
      <tr>
      <td style="padding:2.5%;width:63%;vertical-align:middle">
      <p class="name" style="text-align:center;font-size:36px;font-weight:bold;">Jerry (Qilong) Cheng</p>
      <p style="font-size:15px;">
      I am a <b>Research Fellow</b> at <a href="https://haosu-robotics.github.io">New York University’s Biomechatronics and Intelligent Robotics Lab</a>, advised by <b>Prof. Hao Su</b>. I previously conducted research at the <a href="https://starslab.ca">Space and Terrestrial Autonomous Robotics Systems Lab</a> with <b>Prof. Jonathan Kelly</b>, the <a href="https://danielwigdor.com">Dynamic Graphics Project Lab</a> with <b>Prof. Daniel Wigdor</b>, and the <a href="https://robotics.utoronto.ca">University of Toronto Robotics Institute</a> with <b>Profs. Matthew Mackay</b> and <b>Ali Bereyhi</b>.
      </p>

      <!-- <p style="margin-top:18px;font-size:15px;">
      <b><u>Goal:</u></b> Build robots that <b>empower creativity and intelligence</b>—advancing filmmaking, locomotion, and human–robot collaboration.
      </p> -->

      <p style="margin-top:18px;font-size:15px;">
      <b><u>Research Interest:</u></b> The intersection of <b>robotics</b>, <b>large-scale reinforcement learning</b>, and <b>vision-based control</b>—toward unified frameworks for <b>loco-manipulation</b> and <b>cinematic motion planning</b>.
      </p>

      <p style="margin-top:18px;font-size:15px;">
      <b><u>Research Question:</u></b> How can we design <b>scalable robot learning flywheels</b> that unify perception, whole-body control, and dexterous manipulation—enabling general-purpose, reliable robots in unstructured real-world environments?
      </p>

      <!-- <p style="margin-top:18px;font-size:15px;">
      <b><u>Robots:</u></b> I love building humanoids and cinematic arms that move and perceive as fluidly as humans—bridging art, intelligence, and motion.
      </p> -->

      <p style="margin-top:18px;font-size:15px;">
      <b>Email:</b> <a href="mailto:qilong.cheng@mail.utoronto.ca">qilong.cheng@mail.utoronto.ca</a>
      </p>

      <p style="text-align:center;margin-top:24px;">
      <a href="mailto:qilong.cheng@mail.utoronto.ca">Email</a> &nbsp;/&nbsp;
      <a href="data/resume.pdf">CV</a> &nbsp;/&nbsp;
      <a href="https://scholar.google.com/citations?user=iQuHS3MAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
      <a href="https://www.linkedin.com/in/jerry-qilong-cheng-540039163/">LinkedIn</a> &nbsp;/&nbsp;
      <a href="https://github.com/thejerrycheng">GitHub</a>
      </p>
      </td>
      <td style="padding:2.5%;width:37%;max-width:37%">
      <a href="assets/images/profile_pic.png"><img style="width:100%;border-radius:50%;box-shadow:0 0 10px rgba(0,0,0,0.2);" src="assets/images/profile_pic.png" alt="profile photo"></a>
      </td>
      </tr>
      </tbody>
      </table>
      </body>

    <table style="width:100%;max-width:800px;margin:auto;border-spacing:0px;">
      <tbody>
        <tr><td><h2>Education</h2>
          <p><b><a href="https://www.nyu.edu" target="_blank">New York University</a></b>, Research Fellowship – Biomechatronics and Intelligent Robotics Lab<br>
          <i>Sep 2025 – Aug 2026</i></p>
          <p><b><a href="https://www.utoronto.ca" target="_blank">University of Toronto</a></b>, M.Eng. in Computer Engineering (Robotics), GPA: 3.89/4.00<br>
          <i>Sep 2023 – Aug 2025</i></p>
          <p><b><a href="https://www.utoronto.ca" target="_blank">University of Toronto</a></b>, B.A.Sc. in Mechanical Engineering, Minor in Robotics & Business, Senior GPA: 3.92/4.00<br>
          <i>Aug 2017 – Jun 2023</i></p>
        </td></tr>
      </tbody>
    </table>


    <table style="width:100%;max-width:800px;margin:auto;border-spacing:0px;">
      <tbody>
        <tr><td><h2>Research Interests</h2>
          <p>My research focuses on integrating learning-based control and perception for robots. Specifically, I develop reinforcement learning algorithms for visual loco-manipulation, imitation learning for exoskeletons, and vision-based control frameworks for biped and manipulator robots. I am also exploring unified policies that bridge hardware-aware and perception-driven intelligence.</p>
        </td></tr>
      </tbody>
    </table>

    <table style="width:100%;max-width:800px;margin:auto;border-spacing:0px 10px;border-collapse:separate;">
  <tbody>
    <tr><td><h2>Publications</h2></td></tr>

    <!-- ======= News Section ======= -->
  <table style="width:100%;max-width:800px;margin:auto;border-spacing:0px;margin-top:30px;">
    <tbody>
      <tr>
        <td style="padding:8px;vertical-align:middle;width:70%;">
          <h2 style="margin-bottom:8px;">News</h2>
          <p style="font-size:15px;line-height:1.5em;">
            <b>[09/2025]</b> Invited talk on 
            <i>Scalable Sim-to-Real Learning for General-Purpose Humanoid Skills</i> 
            at <b>GRASP SFI Seminar</b>.
          </p>
        </td>

        <td style="padding:8px;width:30%;vertical-align:middle;text-align:center;">
          <img src="images/news/iros_2025.jpg" alt="GRASP SFI Talk" width="100%" style="border-radius:6px;">
        </td>
      </tr>
    </tbody>
  </table>


    <!-- Publication 1 Robot world problme-->
    <tr onmouseout="pub1_stop()" onmouseover="pub1_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='pub2_image'><video width=100% muted autoplay loop>
          <source src="/" type="video/mp4">
          </video></div>
          <img src='assets/images/publications/pub1.jpg' width="250">
        </div>
        <script type="text/javascript">
          function pub1_start(){document.getElementById('pub1_image').style.opacity="1";}
          function pub1_stop(){document.getElementById('pub1_image').style.opacity="0";}
          pub1_stop();
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2409.17420"><span class="papertitle">A Certifiably Correct Algorithm for Generalized Robot-World and Hand-Eye Calibration</span></a>
        <br>
        E. Wise, P. Kaveti, <b>Q. Cheng</b>, W. Wang, H. Singh, J. Kelly, D. M. Rosen, and M. Giamou
        <br>
        <em>International Journal of Robotics Research (IJRR)</em>, 2025
        <br>
        <a href="https://arxiv.org/abs/2507.23045">arXiv</a>
        <p style="margin-top:6px;font-size:14px;line-height:1.4em;">
          Introduces a certifiably correct calibration algorithm ensuring globally optimal robot-world and hand-eye alignment under general conditions.
        </p>
      </td>
    </tr>

      <!-- Publication 2 -->
      <tr onmouseout="pub2_stop()" onmouseover="pub2_start()">
        <td style="padding:16px;width:20%;vertical-align:middle">
          <div class="one">
            <div class="two" id='pub2_image'><video width=100% muted autoplay loop>
            <source src="images/pub2.mp4" type="video/mp4">
            </video></div>
            <img src='images/pub2.jpg' width="250">
          </div>
          <script type="text/javascript">
            function pub2_start(){document.getElementById('pub2_image').style.opacity="1";}
            function pub2_stop(){document.getElementById('pub2_image').style.opacity="0";}
            pub2_stop();
          </script>
        </td>
        <td style="padding:8px;width:80%;vertical-align:middle">
          <a href="https://arxiv.org/abs/2409.17420"><span class="papertitle">VibraForge: A Scalable Prototyping Toolkit For Creating Spatialized Vibrotactile Feedback Systems</span></a><br>
          B. Huang, S. Ren, Y. Luo, <strong>Q. Cheng</strong>, H. Cai, Y. Sang, M. Sousa, P. H. Dietz, and D. Wigdor<br>
          <em>CHI</em>, 2024<br>
          <a href="https://arxiv.org/abs/2409.17420">arXiv</a>
          <p></p>
          <p>An open-source toolkit enabling rapid design and deployment of large-scale vibrotactile feedback systems for spatialized haptic interactions.</p>
        </td>
      </tr>

    <!-- Publication 3 -->
    <tr onmouseout="pub3_stop()" onmouseover="pub3_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='pub3_image'><video width=100% muted autoplay loop>
          <source src="images/pub3.mp4" type="video/mp4">
          </video></div>
          <img src='images/pub3.jpg' width="250">
        </div>
        <script type="text/javascript">
          function pub3_start(){document.getElementById('pub3_image').style.opacity="1";}
          function pub3_stop(){document.getElementById('pub3_image').style.opacity="0";}
          pub3_stop();
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2407.12105"><span class="papertitle">AeroHaptix: A Wearable Vibrotactile Feedback System for Enhancing Collision Avoidance in UAV Teleoperation</span></a><br>
        B. Huang, Z. Wang, <strong>Q. Cheng</strong>, S. Ren, H. Cai, A. Alvarez Valdivia, K. Mahadevan, and D. Wigdor<br>
        <em>IEEE RA-L</em>, 2024<br>
        <a href="https://arxiv.org/abs/2407.12105">arXiv</a>
        <p></p>
        <p>Introduces a wearable vibrotactile system integrated with UAV teleoperation, leveraging control barrier functions for safe human-drone interaction.</p>
      </td>
    </tr>

    <!-- Publication 4 -->
    <tr onmouseout="pub4_stop()" onmouseover="pub4_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='pub4_image'><video width=100% muted autoplay loop>
          <source src="images/pub4.mp4" type="video/mp4">
          </video></div>
          <img src='images/pub4.jpg' width="250">
        </div>
        <script type="text/javascript">
          function pub4_start(){document.getElementById('pub4_image').style.opacity="1";}
          function pub4_stop(){document.getElementById('pub4_image').style.opacity="0";}
          pub4_stop();
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://ieeexplore.ieee.org/document/10196187"><span class="papertitle">Extrinsic Calibration of 2D Millimetre-Wavelength Radar Pairs Using Ego-Velocity Estimates</span></a><br>
        <strong>Q. Cheng</strong>, E. Wise, and J. Kelly<br>
        <em>IEEE AIM</em>, 2023<br>
        <a href="https://ieeexplore.ieee.org/document/10196187">IEEE</a>
        <p></p>
        <p>Proposes a calibration framework for radar-radar pairs leveraging ego-motion cues without overlapping views for improved pose estimation accuracy.</p>
      </td>
    </tr>

    <!-- Publication 5 -->
    <tr onmouseout="pub5_stop()" onmouseover="pub5_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='pub5_image'><video width=100% muted autoplay loop>
          <source src="images/pub5.mp4" type="video/mp4">
          </video></div>
          <img src='images/pub5.jpg' width="250">
        </div>
        <script type="text/javascript">
          function pub5_start(){document.getElementById('pub5_image').style.opacity="1";}
          function pub5_stop(){document.getElementById('pub5_image').style.opacity="0";}
          pub5_stop();
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://ieeexplore.ieee.org/abstract/document/10256219"><span class="papertitle">Spatiotemporal Calibration of 3D Millimetre-Wavelength Radar-Camera Pairs</span></a><br>
        E. Wise, <strong>Q. Cheng</strong>, and J. Kelly<br>
        <em>IEEE TRO</em>, 2022<br>
        <a href="https://ieeexplore.ieee.org/abstract/document/10256219">IEEE</a>
        <p></p>
        <p>Introduces continuous-time B-spline calibration for radar-camera systems, outperforming state-of-the-art methods in robustness and precision.</p>
      </td>
    </tr>

    <!-- Publication 6 -->
    <tr onmouseout="pub6_stop()" onmouseover="pub6_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='pub6_image'><video width=100% muted autoplay loop>
          <source src="images/pub6.mp4" type="video/mp4">
          </video></div>
          <img src='images/pub6.jpg' width="250">
        </div>
        <script type="text/javascript">
          function pub6_start(){document.getElementById('pub6_image').style.opacity="1";}
          function pub6_stop(){document.getElementById('pub6_image').style.opacity="0";}
          pub6_stop();
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://ieeexplore.ieee.org/document/9745100"><span class="papertitle">Weakly Supervised Semantic and Attentive Data Mixing Augmentation for Fine-Grained Visual Categorization</span></a><br>
        M. He, <strong>Q. Cheng</strong>, and G. Qi<br>
        <em>IEEE Access</em>, 2022<br>
        <a href="https://ieeexplore.ieee.org/document/9745100">IEEE</a>
        <p></p>
        <p>Proposes a weakly supervised attention-guided data augmentation strategy for fine-grained image classification tasks.</p>
      </td>
    </tr>

    <!-- Publication 7 -->
    <tr onmouseout="pub7_stop()" onmouseover="pub7_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='pub7_image'><video width=100% muted autoplay loop>
          <source src="images/pub7.mp4" type="video/mp4">
          </video></div>
          <img src='images/pub7.jpg' width="250">
        </div>
        <script type="text/javascript">
          function pub7_start(){document.getElementById('pub7_image').style.opacity="1";}
          function pub7_stop(){document.getElementById('pub7_image').style.opacity="0";}
          pub7_stop();
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://nanolithography.spiedigitallibrary.org/conference-proceedings-of-spie/12253/122530A/Generative-design-for-self-balancing-unicycle-robot-in-additive-manufacturing/10.1117/12.2639454.short"><span class="papertitle">Generative Design for Self-Balancing Unicycle Robot in Additive Manufacturing</span></a><br>
        J. Chen, <strong>Q. Cheng</strong>, and M. Han<br>
        <em>SPIE ACAIB</em>, 2022<br>
        <a href="https://nanolithography.spiedigitallibrary.org/conference-proceedings-of-spie/12253/122530A/Generative-design-for-self-balancing-unicycle-robot-in-additive-manufacturing/10.1117/12.2639454.short">SPIE</a>
        <p></p>
        <p>Applies generative design and additive manufacturing techniques to develop a self-balancing unicycle robot prototype.</p>
      </td>
    </tr>
  </tbody>
</table>

    </table>

    <table style="width:100%;max-width:800px;margin:auto;border-spacing:0px;">
      <tbody>
        <tr><td><h2>Research Experience</h2>
          <ul>
            <li><b>Research Fellow</b> – Biomechatronics and Intelligent Robotics Lab, NYU (Prof. Hao Su) <i>(Sep 2025 – Present)</i><br>Developed reinforcement learning and musculoskeletal simulation frameworks for exoskeleton and humanoid locomotion benchmarking.</li>
            <li><b>Robotics Researcher</b> – STARS Lab, University of Toronto (Prof. Jonathan Kelly) <i>(Sep 2021 – Aug 2025)</i><br>Developed radar-based calibration and state estimation algorithms validated on real-world driving datasets.</li>
            <li><b>HCI Researcher</b> – Dynamic Graphics Project Lab, UofT (Prof. Daniel Wigdor) <i>(Sep 2022 – Aug 2025)</i><br>Created open-source vibrotactile prototyping and wearable haptics systems integrated with UAV teleoperation.</li>
            <li><b>M.Eng Researcher</b> – UofT Robotics Institute <i>(Sep 2024 – Aug 2025)</i><br>Designed and built IRIS: a modular 6-DOF 3D-printed cinema robot arm with imitation learning and visual planning.</li>
          </ul>
        </td></tr>
      </tbody>
    </table>

    <table style="width:100%;max-width:800px;margin:auto;border-spacing:0px;">
      <tbody>
        <tr><td><h2>Technical Skills</h2>
          <p><b>Software & Tools:</b> Python, C++, MATLAB, ROS, MuJoCo, Isaac Sim, IsaacLab, PyTorch, Docker, Linux<br>
          <b>Hardware & Robots:</b> xArm, Unitree, Raspberry Pi, Jetson, Intel RealSense, Arduino, STM32, PND Adam, Booster Robot</p>
        </td></tr>
      </tbody>
    </table>
  </body>
</html>
