<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Jerry (Qilong) Cheng</title>
    <meta name="author" content="Jerry Cheng">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
  </head>

  <body>
    <table style="width:100%;max-width:800px;margin:auto;border-spacing:0px;">
      <tbody>
        <tr>
          <td style="padding:2.5%;width:63%;vertical-align:middle">
            <p class="name" style="text-align:center;">Jerry (Qilong) Cheng</p>
            <p>
              I am a robotics researcher and engineer passionate about developing unified policies that integrate visual perception, loco-manipulation, and dexterous control for intelligent robotic systems. My work spans reinforcement learning, control, and mechanism design for humanoid and cinematic robots. I am currently a Research Fellow at <a href="https://haosu-robotics.github.io">NYU Biomechatronics and Intelligent Robotics Lab</a> under Prof. Hao Su, and previously at the <a href="https://starslab.ca">Space and Terrestrial Autonomous Robotics Systems Lab</a> under Prof. Jonathan Kelly.
            </p>
            <p style="text-align:center">
              <a href="mailto:qilong.cheng@mail.utoronto.ca">Email</a> &nbsp;/&nbsp;
              <a href="data/Robotics_Resume-9.pdf">CV</a> &nbsp;/&nbsp;
              <a href="https://scholar.google.com/citations?user=iQuHS3MAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
              <a href="https://www.linkedin.com/in/jerry-qilong-cheng-540039163/">LinkedIn</a> &nbsp;/&nbsp;
              <a href="https://github.com/thejerrycheng">GitHub</a>
            </p>
          </td>
          <td style="padding:2.5%;width:37%;max-width:37%">
            <a href="images/jerry.jpg"><img style="width:100%;border-radius:50%;" src="images/jerry.jpg" alt="profile photo"></a>
          </td>
        </tr>
      </tbody>
    </table>

    <table style="width:100%;max-width:800px;margin:auto;border-spacing:0px;">
      <tbody>
        <tr><td><h2>Education</h2>
          <p><b>University of Toronto</b>, M.Eng. in Computer Engineering (Robotics), GPA: 3.89/4.00<br>
          <i>Sep 2023 – Aug 2025</i></p>
          <p><b>University of Toronto</b>, B.A.Sc. in Mechanical Engineering, Minor in Robotics & Business, GPA: 3.92/4.00<br>
          <i>Aug 2017 – Jun 2023</i></p>
        </td></tr>
      </tbody>
    </table>

    <table style="width:100%;max-width:800px;margin:auto;border-spacing:0px;">
      <tbody>
        <tr><td><h2>Research Interests</h2>
          <p>My research focuses on integrating learning-based control and perception for robots. Specifically, I develop reinforcement learning algorithms for visual loco-manipulation, imitation learning for exoskeletons, and vision-based control frameworks for biped and manipulator robots. I am also exploring unified policies that bridge hardware-aware and perception-driven intelligence.</p>
        </td></tr>
      </tbody>
    </table>

    <table style="width:100%;max-width:800px;margin:auto;border-spacing:0px 10px;border-collapse:separate;">
  <tbody>
    <tr><td><h2>Publications</h2></td></tr>

    <!-- Publication 1 -->
    <tr onmouseout="pub1_stop()" onmouseover="pub1_start()" bgcolor="#ffffd0">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='pub1_image'><video width=100% muted autoplay loop>
          <source src="images/pub1.mp4" type="video/mp4">
          </video></div>
          <img src='images/pub1.jpg' width="160">
        </div>
        <script type="text/javascript">
          function pub1_start(){document.getElementById('pub1_image').style.opacity="1";}
          function pub1_stop(){document.getElementById('pub1_image').style.opacity="0";}
          pub1_stop();
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2507.23045"><span class="papertitle">A Certifiably Correct Algorithm for Generalized Robot-World and Hand-Eye Calibration</span></a><br>
        E. Wise, P. Kaveti, <strong>Q. Cheng</strong>, W. Wang, H. Singh, J. Kelly, D. M. Rosen, and M. Giamou<br>
        <em>IJRR</em>, 2025<br>
        <a href="https://arxiv.org/abs/2507.23045">arXiv</a>
        <p></p>
        <p>Introduces a certifiably correct calibration algorithm ensuring globally optimal robot-world and hand-eye alignment under general conditions.</p>
      </td>
    </tr>

    <!-- Publication 2 -->
    <tr onmouseout="pub2_stop()" onmouseover="pub2_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='pub2_image'><video width=100% muted autoplay loop>
          <source src="images/pub2.mp4" type="video/mp4">
          </video></div>
          <img src='images/pub2.jpg' width="160">
        </div>
        <script type="text/javascript">
          function pub2_start(){document.getElementById('pub2_image').style.opacity="1";}
          function pub2_stop(){document.getElementById('pub2_image').style.opacity="0";}
          pub2_stop();
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2409.17420"><span class="papertitle">VibraForge: A Scalable Prototyping Toolkit For Creating Spatialized Vibrotactile Feedback Systems</span></a><br>
        B. Huang, S. Ren, Y. Luo, <strong>Q. Cheng</strong>, H. Cai, Y. Sang, M. Sousa, P. H. Dietz, and D. Wigdor<br>
        <em>CHI</em>, 2024<br>
        <a href="https://arxiv.org/abs/2409.17420">arXiv</a>
        <p></p>
        <p>An open-source toolkit enabling rapid design and deployment of large-scale vibrotactile feedback systems for spatialized haptic interactions.</p>
      </td>
    </tr>

    <!-- Publication 3 -->
    <tr onmouseout="pub3_stop()" onmouseover="pub3_start()" bgcolor="#ffffd0">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='pub3_image'><video width=100% muted autoplay loop>
          <source src="images/pub3.mp4" type="video/mp4">
          </video></div>
          <img src='images/pub3.jpg' width="160">
        </div>
        <script type="text/javascript">
          function pub3_start(){document.getElementById('pub3_image').style.opacity="1";}
          function pub3_stop(){document.getElementById('pub3_image').style.opacity="0";}
          pub3_stop();
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2407.12105"><span class="papertitle">AeroHaptix: A Wearable Vibrotactile Feedback System for Enhancing Collision Avoidance in UAV Teleoperation</span></a><br>
        B. Huang, Z. Wang, <strong>Q. Cheng</strong>, S. Ren, H. Cai, A. Alvarez Valdivia, K. Mahadevan, and D. Wigdor<br>
        <em>IEEE RA-L</em>, 2024<br>
        <a href="https://arxiv.org/abs/2407.12105">arXiv</a>
        <p></p>
        <p>Introduces a wearable vibrotactile system integrated with UAV teleoperation, leveraging control barrier functions for safe human-drone interaction.</p>
      </td>
    </tr>

    <!-- Publication 4 -->
    <tr onmouseout="pub4_stop()" onmouseover="pub4_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='pub4_image'><video width=100% muted autoplay loop>
          <source src="images/pub4.mp4" type="video/mp4">
          </video></div>
          <img src='images/pub4.jpg' width="160">
        </div>
        <script type="text/javascript">
          function pub4_start(){document.getElementById('pub4_image').style.opacity="1";}
          function pub4_stop(){document.getElementById('pub4_image').style.opacity="0";}
          pub4_stop();
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://ieeexplore.ieee.org/document/10196187"><span class="papertitle">Extrinsic Calibration of 2D Millimetre-Wavelength Radar Pairs Using Ego-Velocity Estimates</span></a><br>
        <strong>Q. Cheng</strong>, E. Wise, and J. Kelly<br>
        <em>IEEE AIM</em>, 2023<br>
        <a href="https://ieeexplore.ieee.org/document/10196187">IEEE</a>
        <p></p>
        <p>Proposes a calibration framework for radar-radar pairs leveraging ego-motion cues without overlapping views for improved pose estimation accuracy.</p>
      </td>
    </tr>

    <!-- Publication 5 -->
    <tr onmouseout="pub5_stop()" onmouseover="pub5_start()" bgcolor="#ffffd0">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='pub5_image'><video width=100% muted autoplay loop>
          <source src="images/pub5.mp4" type="video/mp4">
          </video></div>
          <img src='images/pub5.jpg' width="160">
        </div>
        <script type="text/javascript">
          function pub5_start(){document.getElementById('pub5_image').style.opacity="1";}
          function pub5_stop(){document.getElementById('pub5_image').style.opacity="0";}
          pub5_stop();
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://ieeexplore.ieee.org/abstract/document/10256219"><span class="papertitle">Spatiotemporal Calibration of 3D Millimetre-Wavelength Radar-Camera Pairs</span></a><br>
        E. Wise, <strong>Q. Cheng</strong>, and J. Kelly<br>
        <em>IEEE TRO</em>, 2022<br>
        <a href="https://ieeexplore.ieee.org/abstract/document/10256219">IEEE</a>
        <p></p>
        <p>Introduces continuous-time B-spline calibration for radar-camera systems, outperforming state-of-the-art methods in robustness and precision.</p>
      </td>
    </tr>

    <!-- Publication 6 -->
    <tr onmouseout="pub6_stop()" onmouseover="pub6_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='pub6_image'><video width=100% muted autoplay loop>
          <source src="images/pub6.mp4" type="video/mp4">
          </video></div>
          <img src='images/pub6.jpg' width="160">
        </div>
        <script type="text/javascript">
          function pub6_start(){document.getElementById('pub6_image').style.opacity="1";}
          function pub6_stop(){document.getElementById('pub6_image').style.opacity="0";}
          pub6_stop();
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://ieeexplore.ieee.org/document/9745100"><span class="papertitle">Weakly Supervised Semantic and Attentive Data Mixing Augmentation for Fine-Grained Visual Categorization</span></a><br>
        M. He, <strong>Q. Cheng</strong>, and G. Qi<br>
        <em>IEEE Access</em>, 2022<br>
        <a href="https://ieeexplore.ieee.org/document/9745100">IEEE</a>
        <p></p>
        <p>Proposes a weakly supervised attention-guided data augmentation strategy for fine-grained image classification tasks.</p>
      </td>
    </tr>

    <!-- Publication 7 -->
    <tr onmouseout="pub7_stop()" onmouseover="pub7_start()" bgcolor="#ffffd0">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='pub7_image'><video width=100% muted autoplay loop>
          <source src="images/pub7.mp4" type="video/mp4">
          </video></div>
          <img src='images/pub7.jpg' width="160">
        </div>
        <script type="text/javascript">
          function pub7_start(){document.getElementById('pub7_image').style.opacity="1";}
          function pub7_stop(){document.getElementById('pub7_image').style.opacity="0";}
          pub7_stop();
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://nanolithography.spiedigitallibrary.org/conference-proceedings-of-spie/12253/122530A/Generative-design-for-self-balancing-unicycle-robot-in-additive-manufacturing/10.1117/12.2639454.short"><span class="papertitle">Generative Design for Self-Balancing Unicycle Robot in Additive Manufacturing</span></a><br>
        J. Chen, <strong>Q. Cheng</strong>, and M. Han<br>
        <em>SPIE ACAIB</em>, 2022<br>
        <a href="https://nanolithography.spiedigitallibrary.org/conference-proceedings-of-spie/12253/122530A/Generative-design-for-self-balancing-unicycle-robot-in-additive-manufacturing/10.1117/12.2639454.short">SPIE</a>
        <p></p>
        <p>Applies generative design and additive manufacturing techniques to develop a self-balancing unicycle robot prototype.</p>
      </td>
    </tr>
  </tbody>
</table>

    </table>

    <table style="width:100%;max-width:800px;margin:auto;border-spacing:0px;">
      <tbody>
        <tr><td><h2>Research Experience</h2>
          <ul>
            <li><b>Research Fellow</b> – Biomechatronics and Intelligent Robotics Lab, NYU (Prof. Hao Su) <i>(Sep 2025 – Present)</i><br>Developed reinforcement learning and musculoskeletal simulation frameworks for exoskeleton and humanoid locomotion benchmarking.</li>
            <li><b>Robotics Researcher</b> – STARS Lab, University of Toronto (Prof. Jonathan Kelly) <i>(Sep 2021 – Aug 2025)</i><br>Developed radar-based calibration and state estimation algorithms validated on real-world driving datasets.</li>
            <li><b>HCI Researcher</b> – Dynamic Graphics Project Lab, UofT (Prof. Daniel Wigdor) <i>(Sep 2022 – Aug 2025)</i><br>Created open-source vibrotactile prototyping and wearable haptics systems integrated with UAV teleoperation.</li>
            <li><b>M.Eng Researcher</b> – UofT Robotics Institute <i>(Sep 2024 – Aug 2025)</i><br>Designed and built IRIS: a modular 6-DOF 3D-printed cinema robot arm with imitation learning and visual planning.</li>
          </ul>
        </td></tr>
      </tbody>
    </table>

    <table style="width:100%;max-width:800px;margin:auto;border-spacing:0px;">
      <tbody>
        <tr><td><h2>Technical Skills</h2>
          <p><b>Software & Tools:</b> Python, C++, MATLAB, ROS, MuJoCo, Isaac Sim, IsaacLab, PyTorch, Docker, Linux<br>
          <b>Hardware & Robots:</b> xArm, Unitree, Raspberry Pi, Jetson, Intel RealSense, Arduino, STM32, PND Adam, Booster Robot</p>
        </td></tr>
      </tbody>
    </table>
  </body>
</html>
